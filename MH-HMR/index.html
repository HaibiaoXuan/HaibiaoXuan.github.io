<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="MH-HMR: Human Mesh Recovery from Monocular Images via Multi-Hypothesis Learning">
  <meta name="keywords" content="Human Mesh Recovery, Monocular Image, Multi-Hypothesis">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>MH-HMR Project Page</title>


  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://mrtornado24.github.io/">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://mrtornado24.github.io/FENeRF/">
            FENeRF
          </a>
          <a class="navbar-item" href="https://mrtornado24.github.io/IDE-3D/">
            IDE-3D
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> --> 


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">MH-HMR: Human Mesh Recovery from Monocular Images via Multi-Hypothesis Learning</h1>
          <!-- <h1 class="title is-size-3" style="color:#5a6268;"> ICCV 2023 </h1> -->
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://haibiaoxuan.github.io/">Haibiao Xuan</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://zhangjinso.github.io/">Jinsong Zhang</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="http://cic.tju.edu.cn/faculty/likun/">Kun Li</a><sup>1,*</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Tianjin University,</span>
            <span class="author-block"><sup>*</sup>Corresponding author</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="./images/Paper.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/xxxx"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
			    <!-- https://www.youtube.com/watch?v=xxxx -->
                <a href="http://cic.tju.edu.cn/faculty/likun/projects/MHPro/imgs/demo.mp4"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/HaibiaoXuan/MH-HMR"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
             

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Nerfies</span> turns selfie videos from your phone into
        free-viewpoint
        portraits.
      </h2>
    </div>
  </div>
</section> -->


<!--<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item case_00">
          <video poster="" id="case_00" autoplay controls muted loop playsinline height="100%">
            <source src="./images/case_00_00.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
	    Recovering 3D human meshes from monocular images is an inherently ill-posed and challenging task due to depth ambiguity, joint occlusion, and truncation. 
	    However, most existing approaches do not model such uncertainties, typically yielding a single reconstruction for one input. 
            In contrast, this paper embraces the ambiguity of the reconstruction and considers the problem as an inverse problem for which multiple feasible solutions exist. 
	    To address these issues, we propose a multi-hypothesis approach, MH-HMR, to efficiently model the multi-hypothesis representation and build strong relationships among the hypothetical features. Specifically, the task is decomposed into three stages: 
	    (1) generating a reasonable set of initial recovery results (i.e., multiple hypotheses) given a single color image; (2) modeling intrahypothesis refinement to enhance every single-hypothesis feature; (3) establishing inter-hypothesis communication and regressing the final human meshes. 
	    Meanwhile, we further take advantage of multiple hypotheses and our recovery process to achieve human mesh recovery from multiple uncalibrated views. 
            Compared with state-of-the-art methods, our approach MH-HMR achieves superior performance and recovers more accurate human meshes on challenging benchmark datasets like Human3.6M and 3DPW, while demonstrating our effectiveness across a variety of settings. 
            The code will be publicly available for research purposes.            
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <!-- https://www.youtube.com/embed/xxxxx?rel=0&amp;showinfo=0 -->
	  <a href="http://cic.tju.edu.cn/faculty/likun/projects/MHPro/imgs/demo.mp4">
          <video poster="" id="pixar_00" autoplay controls muted loop playsinline height="100%">
            <source src="http://cic.tju.edu.cn/faculty/likun/projects/MHPro/imgs/demo.mp4" type="video/mp4">
	  </a>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>

<hr/>

<section class="section">

  <div class="container is-max-desktop">
    <div class="content has-text-justified">
      <h2 class="title is-3 has-text-centered"><p>Teaser</p></h2>
      <div class="has-text-centered">
        <img style="width: 100%;" src="./images/Teaser.png"
             alt="MH-HMR teaser."/>
      </div>
      <p>
        We propose a multi-hypothesis method to recover a 3D human mesh from a monocular image. 
        Right: results of the probabilistic method ProHMR [11], the state-of-the-art (SOTA) method PARE [9] and our method for a challenging image.
      </p>
    </div>
  </div>

  <br/>
  
  <div class="container is-max-desktop">
    <div class="content has-text-justified">
      <h2 class="title is-3 has-text-centered"><p>Framework Overview</p></h2>
      <div class="has-text-centered">
        <img style="width: 100%;" src="./images/Pipeline.png"
             alt="MH-HMR architecture."/>
      </div>
      <p>
        Overview of the proposed method. Given an input monocular image I, 
        we perform probabilistic modeling (a) with normalizing flows to extract image features, predict a pose distribution and generate multiple initial human mesh hypotheses (where N indicates the number of hypotheses), 
        input these multi-hypotheses into the Intra-hypothesis refinement module (b) for independent refinement and feature enhancement, 
        use the Inter-hypothesis communication module (c) to implement their communication, and finally regress to obtain the recovered human mesh M.
      </p>
    </div>
  </div>

  <br/>

  <div class="container is-max-desktop">
    <div class="content has-text-justified">
      <h2 class="title is-3 has-text-centered"><p>Results</p></h2>
      <div class="has-text-centered">
        <img style="width: 100%;" src="./images/Results_1.png"
             alt="MH-HMR comparison results."/>
        <p>
          Qualitative results on LSP dataset. From left to right shows the input images, and the results of ProHMR, PyMAF, PARE and ours.
        </p>
      </div>
      <div class="has-text-centered">
        <img style="width: 100%;" src="./images/Results_2.png"
             alt="MH-HMR additional results."/>
        <p>
          Plausible human mesh recovery results generated by our method, especially for ambiguous parts with depth ambiguity, joint occlusion and truncation..
        </p>
      </div>
      
    </div>
  </div>

  <br/>
 
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{xuan2022mhpro,
  title={MHPro: Multi-hypothesis Probabilistic Modeling for Human Mesh Recovery},
  author={Xuan, Haibiao and Zhang, Jinsong and Li, Kun},
  booktitle={Artificial Intelligence: Second CAAI International Conference, CICAI 2022, Beijing, China, August 27--28, 2022, Revised Selected Papers, Part I},
  pages={216--228},
  year={2022},
  organization={Springer}
  }</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      Thanks to <a href="https://www.flaticon.com/" target="_blank">Flaticon</a> for providing beautiful icons.
    </div>
  </div>
</footer>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-F5RT7HMEN2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-F5RT7HMEN2');
</script>

<script type="text/javascript" src="./static/slick/slick.min.js"></script>
</body>
</html>
